{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vegam_task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvKnqRskEDVpbFyiw9rbkD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/digs1998/Audio-Classification-Cats-and-Dogs/blob/main/Vegam_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PvuFjJMX7I8",
        "outputId": "f27d12ec-cb31-4805-a56b-b9665f4693b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAky6xoDYB4B"
      },
      "source": [
        "import os\n",
        "import librosa.display as lbd\n",
        "import librosa \n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import scipy.io.wavfile as sci_wav\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "yO4nEI1aYLCH",
        "outputId": "6996bff1-f6d8-4573-c82c-888429f88790"
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Deep learning task-20210403T043535Z-001/Deep learning task/train_test_split.csv')\n",
        "train_data.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>test_cat</th>\n",
              "      <th>test_dog</th>\n",
              "      <th>train_cat</th>\n",
              "      <th>train_dog</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>cat_22.wav</td>\n",
              "      <td>dog_barking_97.wav</td>\n",
              "      <td>cat_99.wav</td>\n",
              "      <td>dog_barking_33.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>cat_116.wav</td>\n",
              "      <td>dog_barking_0.wav</td>\n",
              "      <td>cat_54.wav</td>\n",
              "      <td>dog_barking_86.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>cat_155.wav</td>\n",
              "      <td>dog_barking_93.wav</td>\n",
              "      <td>cat_34.wav</td>\n",
              "      <td>dog_barking_45.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>cat_58.wav</td>\n",
              "      <td>dog_barking_10.wav</td>\n",
              "      <td>cat_132.wav</td>\n",
              "      <td>dog_barking_76.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     test_cat            test_dog    train_cat           train_dog\n",
              "0           0   cat_22.wav  dog_barking_97.wav   cat_99.wav  dog_barking_33.wav\n",
              "1           1  cat_116.wav   dog_barking_0.wav   cat_54.wav  dog_barking_86.wav\n",
              "2           2  cat_155.wav  dog_barking_93.wav   cat_34.wav  dog_barking_45.wav\n",
              "3           3   cat_58.wav  dog_barking_10.wav  cat_132.wav  dog_barking_76.wav"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOKPlhfIYVs_"
      },
      "source": [
        "#making training, test separate dfs\n",
        "cat_train = train_data[['train_cat']].dropna().rename(index=str, columns={\"train_cat\":\"file\"}).assign(label=0)\n",
        "\n",
        "dog_train = train_data[['train_dog']].dropna().rename(index=str, columns={\"train_dog\":\"file\"}).assign(label=1)\n",
        "\n",
        "cat_test = train_data[['test_cat']].dropna().rename(index=str, columns={\"test_cat\":\"file\"}).assign(label=0)\n",
        "\n",
        "dog_test = train_data[['test_dog']].dropna().rename(index=str, columns={\"test_dog\":\"file\"}).assign(label=1)\n",
        "\n",
        "## concatenate all\n",
        "train_df = pd.concat([cat_train, dog_train]).reset_index(drop=True)\n",
        "test_df = pd.concat([cat_test, dog_test]).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "70O12S_YZQ7Y",
        "outputId": "71bb775e-2e23-4e58-c6e9-028b0d16f87f"
      },
      "source": [
        "df = pd.concat([train_df, test_df]).reset_index(drop=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cat_99.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cat_54.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cat_34.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat_132.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cat_124.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>dog_barking_109.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>dog_barking_69.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>dog_barking_77.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>dog_barking_60.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>dog_barking_57.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>277 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    file  label\n",
              "0             cat_99.wav      0\n",
              "1             cat_54.wav      0\n",
              "2             cat_34.wav      0\n",
              "3            cat_132.wav      0\n",
              "4            cat_124.wav      0\n",
              "..                   ...    ...\n",
              "272  dog_barking_109.wav      1\n",
              "273   dog_barking_69.wav      1\n",
              "274   dog_barking_77.wav      1\n",
              "275   dog_barking_60.wav      1\n",
              "276   dog_barking_57.wav      1\n",
              "\n",
              "[277 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zITQeUZnZYuC"
      },
      "source": [
        "## MFCC processing\n",
        "- The MFCC summarises the frequency distribution across the window size, so it is possible to analyse both the frequency and time characteristics of the sound. These audio representations will allow us to identify features for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enOddabVZSOJ"
      },
      "source": [
        "def features(file):\n",
        "  y,sr = librosa.load(file, res_type='kaiser_fast')\n",
        "  mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "  #applying transpose of mfcc and np.mean to get scaled value\n",
        "  mfcc_scaled_feature = np.mean(mfccs.T, axis=0)\n",
        "  return mfcc_scaled_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV35Lbscbq1b"
      },
      "source": [
        "Now applying the function to all the wav files present\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt_V6Qs2bpIY",
        "outputId": "9f802403-15b9-447d-dc25-069b55c55bbb"
      },
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "audio_dataset_path='/content/drive/MyDrive/Deep learning task-20210403T043535Z-001/Deep learning task/full_dataset/'\n",
        "extracted_features = []\n",
        "for idx_num, row in tqdm(df.iterrows()):\n",
        "  file_name = os.path.join(os.path.abspath(audio_dataset_path),str(row[\"file\"]))\n",
        "  final_class_labels=row[\"label\"]\n",
        "  data=features(file_name)\n",
        "  extracted_features.append([data,final_class_labels])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "277it [03:18,  1.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "trA0TVEfefjL",
        "outputId": "9431a6b1-30bc-4878-d27f-fe0474bdb70c"
      },
      "source": [
        "### converting extracted_features to Pandas dataframe\n",
        "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
        "extracted_features_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-237.81186, 147.8731, -100.09769, -0.18745236...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-152.5646, 85.146255, -136.19484, 23.120811, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-316.7891, 126.741776, -5.3124957, -13.759399...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-288.4771, 93.19667, -31.311403, 7.1528773, -...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-274.62314, 73.78443, -53.000587, 81.18064, -...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature  class\n",
              "0  [-237.81186, 147.8731, -100.09769, -0.18745236...      0\n",
              "1  [-152.5646, 85.146255, -136.19484, 23.120811, ...      0\n",
              "2  [-316.7891, 126.741776, -5.3124957, -13.759399...      0\n",
              "3  [-288.4771, 93.19667, -31.311403, 7.1528773, -...      0\n",
              "4  [-274.62314, 73.78443, -53.000587, 81.18064, -...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SOwdaIefZXR"
      },
      "source": [
        "**Now we split the data into dependent and independent sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ4f9jllfU7s"
      },
      "source": [
        "x = np.array(extracted_features_df['feature'].tolist())\n",
        "y = np.array(extracted_features_df['class'].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ef8SiIui83W"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKJpwg8Dfytv",
        "outputId": "14c0ebfc-e236-4860-eb5c-2acbe38843a0"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=45)\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(221, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTxYugF_i31p"
      },
      "source": [
        "## Machine Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eizCHicogO_O",
        "outputId": "80ca5bc3-67a5-4515-e787-130f71f66616"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe = Pipeline([ ('scaler', MinMaxScaler()),\n",
        "                 ('classifier', RandomForestClassifier())])\n",
        "pipe.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
              "                ('classifier',\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZHs8rJnhHFZ",
        "outputId": "0c3dadab-56fd-4192-b310-b5687337df64"
      },
      "source": [
        "pipe.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzI1-HDzhKED",
        "outputId": "69c7dfa2-ee8d-4e76-c477-2583cf75afa2"
      },
      "source": [
        "y_pred = pipe.predict(x_test)\n",
        "\n",
        "print('Classification Report \\n{}'.format(sklearn.metrics.classification_report(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        34\n",
            "           1       1.00      0.68      0.81        22\n",
            "\n",
            "    accuracy                           0.88        56\n",
            "   macro avg       0.91      0.84      0.86        56\n",
            "weighted avg       0.90      0.88      0.87        56\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX8pMoPDiySL"
      },
      "source": [
        "## Cross Val Score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePFED3RhhifG",
        "outputId": "5853c78f-5448-4bc4-c61b-44cae95f6416"
      },
      "source": [
        "cv=4\n",
        "score = cross_val_score(pipe, x,y, cv=cv)\n",
        "print('Cross-validation score for {cv} folds is \\n{score}'.format(cv = cv, score = score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation score for 4 folds is \n",
            "[0.9        0.89855072 0.85507246 0.86956522]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRPe_9sejX1R"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9nCktib0hxk3",
        "outputId": "6abcdb17-21c2-4c2e-bbff-f3e0bc392fc0"
      },
      "source": [
        "sns.heatmap(sklearn.metrics.confusion_matrix(y_test, y_pred),annot=True, cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2f97b49d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUQbCUUQX_zK"
      },
      "source": [
        "## ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3h4Do5bjkpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001581af-e13a-4d17-cc6e-8f059f7be83c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(40,)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15, batch_size=64, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "4/4 [==============================] - 1s 70ms/step - loss: 11.1894 - accuracy: 0.4484 - val_loss: 0.9562 - val_accuracy: 0.6964\n",
            "Epoch 2/15\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 8.0315 - accuracy: 0.5696 - val_loss: 0.6349 - val_accuracy: 0.7857\n",
            "Epoch 3/15\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.3780 - accuracy: 0.5643 - val_loss: 0.6745 - val_accuracy: 0.7500\n",
            "Epoch 4/15\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.8132 - accuracy: 0.6235 - val_loss: 0.5623 - val_accuracy: 0.8571\n",
            "Epoch 5/15\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 6.5880 - accuracy: 0.6219 - val_loss: 0.6851 - val_accuracy: 0.7679\n",
            "Epoch 6/15\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.8645 - accuracy: 0.6729 - val_loss: 0.9466 - val_accuracy: 0.7500\n",
            "Epoch 7/15\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.9844 - accuracy: 0.5276 - val_loss: 1.0952 - val_accuracy: 0.7500\n",
            "Epoch 8/15\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.3951 - accuracy: 0.6271 - val_loss: 1.0632 - val_accuracy: 0.7321\n",
            "Epoch 9/15\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.2785 - accuracy: 0.6336 - val_loss: 0.9490 - val_accuracy: 0.7679\n",
            "Epoch 10/15\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.5518 - accuracy: 0.7056 - val_loss: 0.9130 - val_accuracy: 0.7679\n",
            "Epoch 11/15\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.9241 - accuracy: 0.7147 - val_loss: 0.8975 - val_accuracy: 0.7857\n",
            "Epoch 12/15\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.3977 - accuracy: 0.6632 - val_loss: 0.8926 - val_accuracy: 0.7679\n",
            "Epoch 13/15\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.7347 - accuracy: 0.6510 - val_loss: 0.8104 - val_accuracy: 0.7857\n",
            "Epoch 14/15\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.3412 - accuracy: 0.7149 - val_loss: 0.7379 - val_accuracy: 0.8393\n",
            "Epoch 15/15\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.7229 - accuracy: 0.6359 - val_loss: 0.6938 - val_accuracy: 0.8393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqlsM_PQWN6j",
        "outputId": "b17d5b5c-149a-4139-cd0a-444f5612d5e8"
      },
      "source": [
        "test_accuracy=model.evaluate(x_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8392857313156128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "vo_QBWIzYZ39",
        "outputId": "fa6d52b3-2957-433b-ca3c-cc250e20900f"
      },
      "source": [
        "sns.heatmap(sklearn.metrics.confusion_matrix(model.predict_classes(x_test), y_test),annot=True, cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2f9b626d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5oP6eoKYmnM",
        "outputId": "9b97c68e-9819-4017-ed32-a38ff2d06c45"
      },
      "source": [
        "print('Classification Report \\n{}'.format(sklearn.metrics.classification_report(y_test, model.predict_classes(x_test))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.87        34\n",
            "           1       0.78      0.82      0.80        22\n",
            "\n",
            "    accuracy                           0.84        56\n",
            "   macro avg       0.83      0.84      0.83        56\n",
            "weighted avg       0.84      0.84      0.84        56\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPdwkxcbZeMb"
      },
      "source": [
        "# Models Testing on Data\n",
        "\n",
        "## RandomForest Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2YZIAaPZTjb",
        "outputId": "4ce866cb-ca44-4bd2-ac9e-20c84844a25a"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "filename=\"/content/drive/MyDrive/Deep learning task-20210403T043535Z-001/Deep learning task/full_dataset/dog_barking_0.wav\"\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "\n",
        "\n",
        "predicted_label=pipe.predict_proba(mfccs_scaled_features)\n",
        "print(predicted_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.11 0.89]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9121zU7aUcS"
      },
      "source": [
        "## ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgGcw3e5aGER",
        "outputId": "d8659c98-e4b8-4f50-decf-3892d65d26dd"
      },
      "source": [
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "\n",
        "\n",
        "predicted_label=model.predict_classes(mfccs_scaled_features)\n",
        "print(predicted_label)\n",
        "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
        "prediction_class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyFl_isnaa16"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}